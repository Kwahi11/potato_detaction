import random
import sys
import cv2
import numpy as np
import time
import collections
import socket
import json
from PyQt5.QtCore import QThread, pyqtSignal, QMutex
from PyQt5.QtGui import QImage, QPixmap, QFont
from PyQt5.QtCore import Qt  # æ·»åŠ åˆ°ç°æœ‰çš„å¯¼å…¥è¯­å¥ä¸­
from PyQt5.QtWidgets import QApplication, QWidget, QLabel, QPushButton, QVBoxLayout, QHBoxLayout, QTextEdit, \
    QGridLayout, QComboBox
from test_yolo6 import detect_objects
from ultralytics import YOLO
from fengzhuangwutu import daoju

import numpy as np
import math
import time

sys.path.append(r"F:\YOLOV8\PotatoDetection-main\MV Viewer\Development\Samples\Python\IMV\opencv_byGetFrame")
from open_cv_show1 import *

import time
from collections import deque

import threading
import time
from pymodbus.client import ModbusTcpClient

plc_mw3_flag = 0  # é»˜è®¤å‘0
plc_enabled = True
# plc_enabled = False

def send_mw3_value(value, plc_enabled):
    print(f"ğŸ›°ï¸ å†™å…¥ PLC: %MW3 = {value}")
    if not plc_enabled:
        print(" æ¨¡æ‹Ÿæ¨¡å¼ï¼šæœªå‘é€ï¼Œä»…æ‰“å°")
        return

    PLC_IP = "192.168.1.88"
    PLC_PORT = 502
    REGISTER_ADDR = 3  # å¯¹åº” %MW3

    client = ModbusTcpClient(PLC_IP, port=PLC_PORT)
    if client.connect():
        result = client.write_register(REGISTER_ADDR, value)
        if not result.isError():
            print(f" æˆåŠŸå†™å…¥: %MW3 = {value}")
        else:
            print(" å†™å…¥å¤±è´¥:", result)
        client.close()
    else:
        print("æ— æ³•è¿æ¥ PLC")

def mw3_loop_thread():
    global plc_mw3_flag
    sequence = [1, 2]
    idx = 0

    while True:
        if not plc_enabled:
            time.sleep(0.5)
            continue

        # æ ¹æ®æ ‡å¿—å†³å®šæ˜¯å¦å‘1/2 æˆ– 0
        value_to_send = plc_mw3_flag if plc_mw3_flag in [0] else sequence[idx % len(sequence)]
        idx += 1 if plc_mw3_flag != 0 else 0

        # å‘é€å€¼
        send_mw3_value(value_to_send, plc_enabled=True)

        time.sleep(0.5)


class CameraThread(QThread):
    """æ‘„åƒå¤´çº¿ç¨‹"""
    frame_signal = pyqtSignal(np.ndarray)

    def __init__(self):
        super().__init__()
        self.running = False
        self.cap = None
        self.current_frame = None
        self.mutex = QMutex()
        self.emit_frame = True  # æ§åˆ¶æ˜¯å¦å‘å‡ºä¿¡å·çš„æ ‡å¿—

        self.frame_max_len = 10
        self.frame_queue = collections.deque(maxlen=self.frame_max_len)

    def run(self):
        """æ‰“å¼€æ‘„åƒå¤´å¹¶æŒç»­è¯»å–ç”»é¢"""
        # self.cap = cv2.VideoCapture(1)
        # if not self.cap.isOpened():
        #     print("Error: æ— æ³•æ‰“å¼€æ‘„åƒå¤´")
        #     return

        self.running = True
        while self.running:
            start_time = time.time()
            # ret, frame = self.cap.read()
            for ret, frame in retrun_frame():

                if ret:
                    # self.frame_queue.append(frame)
                    self.mutex.lock()
                    self.current_frame = frame
                    self.mutex.unlock()
                    # self.frame_signal.emit(fra                    self.current_frame = frameme)
                    if self.emit_frame:  # å¦‚æœå…è®¸å‘å‡ºä¿¡å·
                        self.frame_signal.emit(self.current_frame)  # å‘é€ç”»é¢

                # ç¡çœ é™åˆ¶å–æ¶ˆ
                elapsed_time = time.time() - start_time
                sleep_time = max(0, 0.033 - elapsed_time)  # 30 FPS é™åˆ¶
                time.sleep(sleep_time)
                key = cv2.waitKey(1)
                if key == ord('q'):
                    break

            cv2.destroyAllWindows()
            print("---Demo end---")

    def get_current_frame(self):
        """è·å–å½“å‰å¸§"""
        self.mutex.lock()
        frame = self.current_frame
        self.mutex.unlock()
        return frame

    def set_emit_frame(self, emit_frame):
        """è®¾ç½®æ˜¯å¦å‘å‡ºä¿¡å·"""
        self.mutex.lock()
        self.emit_frame = emit_frame
        self.mutex.unlock()

    def stop(self):
        """å…³é—­æ‘„åƒå¤´"""
        self.running = False
        if self.cap:
            self.cap.release()
        self.quit()
        self.wait()


class YoloThread(QThread):
    """YOLO ç›®æ ‡æ£€æµ‹çº¿ç¨‹"""
    detection_signal = pyqtSignal(list, list,int)
    frame_signal = pyqtSignal(np.ndarray)

    def __init__(self, camera_thread):
        super().__init__()
        self.running = False
        self.camera_thread = camera_thread
        self.model = YOLO('models/best.pt')  # åŠ è½½ YOLO æ¨¡å‹
        self.last_detections = collections.deque(maxlen=30)
        self.alpha = 0.6  # å¹³æ»‘å› å­

        self.frame_max_len = 5
        self.frame_queue = collections.deque(maxlen=self.frame_max_len)

    def run(self):
        """è¿è¡Œ YOLO æ£€æµ‹"""
        self.running = True
        while self.running:
            start_time = time.time()
            frame = self.camera_thread.get_current_frame()
            # self.frame_queue.append(frame)

            if frame is not None:
                # current_frame = self.frame_queue[-1]
                frame, detections, centroids,current_time = detect_objects(frame, self.model)
                detections = self._smooth_detections(detections)

                self.detection_signal.emit(detections, centroids,current_time)
                self.frame_signal.emit(frame)

            elapsed_time = time.time() - start_time
            sleep_time = max(0, 0.1 - elapsed_time)
            time.sleep(sleep_time)

    def _smooth_detections(self, new_detections):
        """æŒ‡æ•°åŠ æƒç§»åŠ¨å¹³å‡ï¼ˆEWMAï¼‰å¹³æ»‘æ£€æµ‹æ¡†"""
        smoothed_detections = []

        for det in new_detections:
            best_match = None
            # éå†æ‰€æœ‰å†å²æ£€æµ‹åˆ—è¡¨ä¸­çš„æ¯ä¸ªæ£€æµ‹é¡¹
            for prev_dets in self.last_detections:
                for prev_det in prev_dets:
                    if self._is_same_target(det, prev_det):
                        best_match = prev_det
                        break  # æ‰¾åˆ°åŒ¹é…åè·³å‡ºå†…å±‚å¾ªç¯
                if best_match:
                    break  # æ‰¾åˆ°åŒ¹é…åè·³å‡ºå¤–å±‚å¾ªç¯

            if best_match:
                # åº”ç”¨å¹³æ»‘
                det["x1"] = int(self.alpha * det["x1"] + (1 - self.alpha) * best_match["x1"])
                det["y1"] = int(self.alpha * det["y1"] + (1 - self.alpha) * best_match["y1"])
                det["x2"] = int(self.alpha * det["x2"] + (1 - self.alpha) * best_match["x2"])
                det["y2"] = int(self.alpha * det["y2"] + (1 - self.alpha) * best_match["y2"])

            smoothed_detections.append(det)

        # å°†å½“å‰å¸§çš„å¹³æ»‘ç»“æœä¿å­˜åˆ°å†å²è®°å½•ä¸­
        self.last_detections.append(smoothed_detections)
        return smoothed_detections

    def _is_same_target(self, det1, det2):
        """åˆ¤æ–­ä¸¤ä¸ªç›®æ ‡æ¡†æ˜¯å¦ä¸ºåŒä¸€ç›®æ ‡"""
        iou_threshold = 0.5
        x1, y1, x2, y2 = det1["x1"], det1["y1"], det1["x2"], det1["y2"]
        x1_, y1_, x2_, y2_ = det2["x1"], det2["y1"], det2["x2"], det2["y2"]

        inter_x1 = max(x1, x1_)
        inter_y1 = max(y1, y1_)
        inter_x2 = min(x2, x2_)
        inter_y2 = min(y2, y2_)

        inter_area = max(0, inter_x2 - inter_x1) * max(0, inter_y2 - inter_y1)
        box1_area = (x2 - x1) * (y2 - y1)
        box2_area = (x2_ - x1_) * (y2_ - y1_)

        iou = inter_area / (box1_area + box2_area - inter_area)
        return iou > iou_threshold

    def stop(self):
        self.running = False
        self.quit()
        self.wait()


class MyWindow(QWidget):
    def __init__(self):
        super().__init__()
        self.initUI()
        self.camera_thread = CameraThread()
        self.camera_thread.frame_signal.connect(self.update_camera_frame)
        self.priority_direction = "ä¸Š"  # é»˜è®¤ä¼˜å…ˆæ–¹å‘
        self.yolo_thread = None  # YOLO æ£€æµ‹çº¿ç¨‹
        self.send_data_enabled = True  # é»˜è®¤å¯ç”¨æ•°æ®å‘é€

        # Socketå®¢æˆ·ç«¯åˆå§‹åŒ–
        self.socket_client = None
        # self.robot_ip = "192.168.32.78"  # æœºæ¢°è‡‚æœåŠ¡å™¨IP
        # self.robot_port = 3367  # æœºæ¢°è‡‚æœåŠ¡å™¨ç«¯å£

        self.robot_ip = "192.168.31.139"  # æœºæ¢°è‡‚æœåŠ¡å™¨IP
        self.robot_port = 3366  # æœºæ¢°è‡‚æœåŠ¡å™¨ç«¯å£
        self.frame_num = 0  # å¸§è®¡æ•°
        self.heartbeat_count = 1  # å¿ƒè·³è®¡æ•°
        self.last_heartbeat_time = 0  # å¿ƒè·³è®¡æ—¶



    def _connect_robot(self):
        """è¿æ¥æœºæ¢°è‡‚æœåŠ¡å™¨"""
        try:
            if self.socket_client is None:
                self.socket_client = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
                self.socket_client.settimeout(3)
                self.socket_client.connect((self.robot_ip, self.robot_port))
                print("æœºæ¢°è‡‚æœåŠ¡å™¨è¿æ¥æˆåŠŸ")
        except Exception as e:
            print(f"è¿æ¥å¤±è´¥: {e}")
            self.socket_client = None

    def _send_data_frame(self, centroids,current_time):
        """å‘é€æ•°æ®å¸§ï¼Œåˆ€å…·è§’åº¦åœ¨ç¬¬ä¸ƒä½"""
        if not self.send_data_enabled:  # å¦‚æœå…³é—­æ•°æ®å‘é€ï¼Œç›´æ¥è¿”å›
            return
        if not self.socket_client:
            self._connect_robot()
            if not self.socket_client:
                return

        try:
            obj_number = len(centroids)
            trigger_time = current_time  # æ—¶é—´æˆ³

            data_header = f"Data;{self.frame_num};{trigger_time};{obj_number};"
            data_body = []
            # angle=random.randint(10,70)

            for idx, (cx, cy, angle) in enumerate(centroids):
                # dx = 640 - cx  # ç¬¬ä¸€æœºæ¢°è‡‚çš„xè½´
                dx=cx           #ç¬¬äºŒä¸ªæœºæ¢°è‡‚çš„Xè½´
                dy = -cy
                angle=-angle
                # cy-=40
                # dx+=5
                # if angle<=-180 or angle>=180:
                #     angle=0;
                # dx = -415
                # cy = 263
                data_body.append(

                    f"{idx},{dx},{dy},0,0,0,{angle},0,0,0,0,0,no"
                    # f"{idx},{dx},{dy},0,0,0,30,0,0,0,0,0,no"
                )
            # if idx>0:
            #     full_data = "STX" + data_header + "|".join(data_body) + "ETX"
            # else:
            #     full_data = "STX" + data_header + "ETX"
            if(len(data_body)!=0):
                 full_data = "STX" + data_header+"|" + "|".join(data_body) + "ETX"
            else:
                 full_data = "STX" + data_header + "ETX"

            self.socket_client.sendall(full_data.encode("ascii"))
            self.frame_num += 1

        except Exception as e:
            print(f"å‘é€æ•°æ®å¸§å¤±è´¥: {e}")
            self.socket_client.close()
            self.socket_client = None

    def _send_heartbeat(self):
        """å‘é€å¿ƒè·³å¸§"""
        if not self.send_data_enabled:  # å¦‚æœå…³é—­æ•°æ®å‘é€ï¼Œç›´æ¥è¿”å›
            return
        if not self.socket_client:
            return

        try:
            current_time = time.time()
            if current_time - self.last_heartbeat_time > 60:  # æ¯åˆ†é’Ÿå‘é€ä¸€æ¬¡
                heartbeat_msg = f"Heart;{self.heartbeat_count};"
                self.socket_client.sendall(heartbeat_msg.encode("ascii"))
                self.heartbeat_count += 1
                self.last_heartbeat_time = current_time
        except Exception as e:
            print(f"å¿ƒè·³å‘é€å¤±è´¥: {e}")
            self.socket_client.close()
            self.socket_client = None

    def initUI(self):
        self.setWindowTitle("é©¬é“ƒè–¯èŠ½çœ¼è¯†åˆ«ç¨‹åº")
        # self.setGeometry(100, 100, 900, 600)
        self.resize(1200, 800)
        self.center_window()
        self.setStyleSheet("background-color: #2E2E2E; color: white;")

        # æ‘„åƒå¤´ç”»é¢
        self.video_label = QLabel(self)
        # self.video_label.setFixedSize(1280, 1024)
        self.video_label.setFixedSize(640, 480)
        self.video_label.setStyleSheet("background-color: black;")
        self.video_label.setScaledContents(True)

        # ç»“æœæ˜¾ç¤ºåŒºåŸŸ
        self.result_text = QTextEdit(self)
        self.result_text.setReadOnly(True)
        self.result_text.setFont(QFont("Arial", 12))
        self.result_text.setStyleSheet("background-color: #1E1E1E; color: #FFD700;")

        # ç»“æœä¿¡æ¯å¸ƒå±€
        self.info_grid = QGridLayout()
        self.info_labels = {}
        info_titles = ["ç±»åˆ«", "ç½®ä¿¡åº¦", "X1", "Y1", "X2", "Y2", "ä¸­å¿ƒåæ ‡X", "ä¸­å¿ƒåæ ‡Y", "ä¼˜å…ˆç›®æ ‡ä¸­å¿ƒX",
                       "ä¼˜å…ˆç›®æ ‡ä¸­å¿ƒY", "åˆ€å…·æ—‹è½¬è§’åº¦"]

        # info_titles = ["ç±»åˆ«", "ç½®ä¿¡åº¦", "X1", "Y1", "X2", "Y2", "ä¸­å¿ƒåæ ‡X", "ä¸­å¿ƒåæ ‡Y", "åˆ€å…·æ—‹è½¬è§’åº¦"]
        for i, title in enumerate(info_titles):
            label = QLabel(f"{title}ï¼š")
            label.setFont(QFont("Arial", 14, QFont.Bold))
            label.setStyleSheet("color: #00FFFF;")
            value = QLabel("0")
            value.setFont(QFont("Arial", 14))
            value.setStyleSheet("color: #FFD700;")
            self.info_labels[title] = value
            self.info_grid.addWidget(label, i, 0)
            self.info_grid.addWidget(value, i, 1)

        # ä¼˜å…ˆç›®æ ‡ä¿¡æ¯
        self.priority_label = QLabel("ä¼˜å…ˆç›®æ ‡ä¿¡æ¯ï¼š")
        self.priority_label.setFont(QFont("Arial", 14, QFont.Bold))
        self.priority_label.setStyleSheet("color: #FF4500;")
        self.priority_info = QTextEdit()
        self.priority_info.setReadOnly(True)
        self.priority_info.setFont(QFont("Arial", 12))
        self.priority_info.setStyleSheet("background-color: #1E1E1E; color: #FFD700;")

        # æ–¹å‘é€‰æ‹©æŒ‰é’®
        self.direction_selector = QComboBox(self)
        self.direction_selector.addItems(["ä¸Š", "ä¸‹", "å·¦", "å³"])
        self.direction_selector.currentIndexChanged.connect(self.change_priority_direction)
        self.direction_label = QLabel("å½“å‰ä¼˜å…ˆæ–¹å‘: ä¸Š")
        self.direction_label.setFont(QFont("Arial", 12, QFont.Bold))
        self.direction_label.setStyleSheet("color: #FFFFFF;")
        # æŒ‰é’®
        self.btn_open_camera = QPushButton("å¼€å¯æ‘„åƒå¤´", self)
        self.btn_open_camera.setStyleSheet("background-color: #4CAF50; color: white;")
        self.btn_open_camera.clicked.connect(self.start_camera)

        self.btn_close_camera = QPushButton("å…³é—­æ‘„åƒå¤´", self)
        self.btn_close_camera.setStyleSheet("background-color: #F44336; color: white;")
        self.btn_close_camera.clicked.connect(self.stop_camera)

        self.btn_start_detection = QPushButton("å¼€å§‹æ£€æµ‹", self)
        self.btn_start_detection.setStyleSheet("background-color: #2196F3; color: white;")
        self.btn_start_detection.clicked.connect(self.start_detection)

        self.btn_stop_detection = QPushButton("å…³é—­æ£€æµ‹", self)
        self.btn_stop_detection.setStyleSheet("background-color: #FF9800; color: white;")
        self.btn_stop_detection.clicked.connect(self.stop_detection)

        # æ·»åŠ æ•°æ®å‘é€å¼€å…³æŒ‰é’®
        self.btn_toggle_send_data = QPushButton("å…³é—­æ•°æ®å‘é€", self)
        self.btn_toggle_send_data.setStyleSheet("background-color: #FF5733; color: white;")
        self.btn_toggle_send_data.clicked.connect(self.toggle_send_data)

        # æŒ‰é’®å¸ƒå±€
        btn_layout = QHBoxLayout()
        btn_layout.addWidget(self.btn_open_camera)
        btn_layout.addWidget(self.btn_close_camera)
        btn_layout.addWidget(self.btn_start_detection)
        btn_layout.addWidget(self.btn_stop_detection)
        btn_layout.addWidget(self.btn_toggle_send_data)

        priority_layout = QVBoxLayout()
        priority_layout.addWidget(self.direction_label)
        priority_layout.addWidget(self.direction_selector)
        priority_layout.addWidget(self.priority_label)
        priority_layout.addWidget(self.priority_info)
        # ä¸»å¸ƒå±€
        main_layout = QHBoxLayout()
        left_layout = QVBoxLayout()
        left_layout.addWidget(self.video_label)
        left_layout.addLayout(btn_layout)
        main_layout.addLayout(left_layout)
        right_layout = QVBoxLayout()
        right_layout.addLayout(self.info_grid)
        main_layout.addLayout(right_layout)

        self.setLayout(main_layout)

    def center_window(self):
        """å°†çª—å£å±…ä¸­æ˜¾ç¤º"""
        # è·å–å±å¹•çš„å‡ ä½•ä¿¡æ¯
        screen = QApplication.primaryScreen().availableGeometry()
        # è·å–çª—å£çš„å‡ ä½•ä¿¡æ¯
        size = self.geometry()
        # è®¡ç®—å±…ä¸­ä½ç½®
        x = (screen.width() - size.width()) // 2
        y = (screen.height() - size.height()) // 2
        # ç§»åŠ¨çª—å£åˆ°è®¡ç®—çš„ä½ç½®
        self.move(x, y)


    def toggle_send_data(self):
        """åˆ‡æ¢æ•°æ®å‘é€çŠ¶æ€"""
        self.send_data_enabled = not self.send_data_enabled
        if self.send_data_enabled:
            self.btn_toggle_send_data.setText("å…³é—­æ•°æ®å‘é€")
            self.btn_toggle_send_data.setStyleSheet("background-color: #FF5733; color: white;")
            print("æ•°æ®å‘é€å·²å¯ç”¨")
        else:
            self.btn_toggle_send_data.setText("å¼€å¯æ•°æ®å‘é€")
            self.btn_toggle_send_data.setStyleSheet("background-color: #4CAF50; color: white;")
            print("æ•°æ®å‘é€å·²å…³é—­")

    def change_priority_direction(self):
        """æ›´æ”¹ä¼˜å…ˆæ–¹å‘"""
        self.priority_direction = self.direction_selector.currentText()
        self.direction_label.setText(f"å½“å‰ä¼˜å…ˆæ–¹å‘: {self.priority_direction}")

    def start_camera(self):
        """å¯åŠ¨æ‘„åƒå¤´"""
        if not self.camera_thread.isRunning():
            self.camera_thread.start()

    def stop_camera(self):
        """å…³é—­æ‘„åƒå¤´"""
        if self.camera_thread.isRunning():
            self.camera_thread.stop()
        self.video_label.clear()
        self.video_label.setStyleSheet("background-color: black;")

    def start_detection(self):
        """å¯åŠ¨ YOLO æ£€æµ‹"""
        if self.yolo_thread is None or not self.yolo_thread.isRunning():
            self.yolo_thread = YoloThread(self.camera_thread)
            # ä¿®æ”¹ä¿¡å·ä¸æ§½çš„è¿æ¥ï¼Œè®© update_detections èƒ½æ¥æ”¶ centroids
            self.camera_thread.set_emit_frame(False)  # ç¦ç”¨ CameraThread çš„ç”»é¢æ›´æ–°
            self.yolo_thread.detection_signal.connect(self.update_detections)
            self.yolo_thread.frame_signal.connect(self.update_camera_frame)
            self.yolo_thread.start()

        global plc_mw3_flag
        print("start_detection plc_mw3_flag = 1")

        # é€šçŸ¥åå°çº¿ç¨‹å¼€å§‹äº¤æ›¿å‘1ã€2
        plc_mw3_flag = 1

    def stop_detection(self):
        """åœæ­¢ YOLO æ£€æµ‹"""
        if self.yolo_thread is not None and self.yolo_thread.isRunning():
            self.yolo_thread.stop()
            self.yolo_thread = None
            self.camera_thread.set_emit_frame(True)  # é‡æ–°å¯ç”¨ CameraThread çš„ç”»é¢æ›´æ–°

        global plc_mw3_flag
        plc_mw3_flag = 0  # å‘é€0

    def update_camera_frame(self, frame):
        """æ›´æ–°æ‘„åƒå¤´ç”»é¢"""
        height, width, channel = frame.shape
        bytes_per_line = 3 * width
        q_image = QImage(frame.data, width, height, bytes_per_line, QImage.Format_RGB888).rgbSwapped()

        pixmap = QPixmap.fromImage(q_image)
        scaled_pixmap = pixmap.scaled(
            self.video_label.width(),
            self.video_label.height(),
            Qt.KeepAspectRatio,  # ä¿æŒå®½é«˜æ¯”
            Qt.SmoothTransformation  # å¹³æ»‘å˜æ¢
        )
        self.video_label.setPixmap(QPixmap.fromImage(q_image))

    def update_detections(self, detections, centroids,current_time):
        """æ›´æ–°æ£€æµ‹ç»“æœ"""
        bug_centers = []
        bugs = [c for c in detections if c['cls'] == 1]

        # åœ¨è¿™é‡ŒåŠ ä¸Šéç©ºåˆ¤æ–­
        if bugs:  # æ£€æŸ¥ bugs åˆ—è¡¨æ˜¯å¦ä¸ºç©º
            for bug in bugs:
                x1, y1, x2, y2 = bug['x1'], bug['y1'], bug['x2'], bug['y2']
                center_x = (x1 + x2) / 2
                center_y = (y1 + y2) / 2
                # å°†ä¸­å¿ƒåæ ‡æ·»åŠ åˆ°åˆ—è¡¨ä¸­
                bug_centers.append((int(center_x), int(center_y)))
        else:
            print("æ²¡æœ‰æ£€æµ‹åˆ°ç±»åˆ«ä¸º1çš„èŠ½çœ¼ã€‚")  # å¦‚æœåˆ—è¡¨ä¸ºç©ºï¼Œè¾“å‡ºæç¤ºä¿¡æ¯
        potatoes = [d for d in detections if d['cls'] == 0]
        if potatoes:
            self.priority_info.setPlainText("\n".join([str(p) for p in potatoes]))
            # è®¡ç®—ä¼˜å…ˆç›®æ ‡
            priority_potato = min(
                potatoes,
                key=lambda p: p['y1'] if self.priority_direction == "ä¸Š" else
                (p['y2'] if self.priority_direction == "ä¸‹" else
                 (p['x1'] if self.priority_direction == "å·¦" else p['x2']))
            )

            # è®¡ç®—ä¼˜å…ˆç›®æ ‡çš„ä¸­å¿ƒåæ ‡
            priority_center_x = (priority_potato["x1"] + priority_potato["x2"]) // 2
            priority_center_y = (priority_potato["y1"] + priority_potato["y2"]) // 2

            self.info_labels["ä¼˜å…ˆç›®æ ‡ä¸­å¿ƒX"].setText(str(priority_center_x))
            self.info_labels["ä¼˜å…ˆç›®æ ‡ä¸­å¿ƒY"].setText(str(priority_center_y))

            self.info_labels["ç±»åˆ«"].setText(str(priority_potato['cls']))
            self.info_labels["ç½®ä¿¡åº¦"].setText(f"{priority_potato['conf']:.2f}")
            self.info_labels["X1"].setText(str(priority_potato['x1']))
            self.info_labels["Y1"].setText(str(priority_potato['y1']))
            self.info_labels["X2"].setText(str(priority_potato['x2']))
            self.info_labels["Y2"].setText(str(priority_potato['y2']))
            self.info_labels["ä¸­å¿ƒåæ ‡X"].setText(str((priority_potato['x1'] + priority_potato['x2']) // 2))
            self.info_labels["ä¸­å¿ƒåæ ‡Y"].setText(str((priority_potato['y1'] + priority_potato['y2']) // 2))

            # self.info_labels["åˆ€å…·æ—‹è½¬è§’åº¦"].setText(f"{centroids[2]}Â°")
            # print("target_angle:", centroids[2])

            if centroids:
                centroid_text = "\\n".join([f"å½¢å¿ƒ: ({cx}, {cy})" for cx, cy, angle in centroids])
                self.result_text.setPlainText(centroid_text)  # æ›´æ–° UI æ˜¾ç¤º
            else:
                self.result_text.clear()
        else:
            self.priority_info.clear()
            for key in self.info_labels:
                self.info_labels[key].setText("0")
        self._send_data_frame(centroids,current_time)  # å‘é€æ•°æ®å¸§

        self._send_heartbeat()  # å‘é€å¿ƒè·³å¸§
        # self._send_to_robot(robot_data)


if __name__ == "__main__":
    app = QApplication(sys.argv)
    window = MyWindow()

    window.show()

    threading.Thread(target=mw3_loop_thread, daemon=True).start()
    sys.exit(app.exec_())
